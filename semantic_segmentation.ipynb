{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8220fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a12703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub[pandas-datasets] in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from kagglehub[pandas-datasets]) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from kagglehub[pandas-datasets]) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
      "Collecting pandas (from kagglehub[pandas-datasets])\n",
      "  Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->kagglehub[pandas-datasets])\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->kagglehub[pandas-datasets])\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\micha\\anaconda3\\envs\\semantic-segmentation\\lib\\site-packages (from tqdm->kagglehub[pandas-datasets]) (0.4.6)\n",
      "Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.0 MB 2.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/11.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.5/11.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 4.3 MB/s eta 0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae635fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/humansintheloop/semantic-segmentation-of-aerial-imagery?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.6M/29.6M [00:05<00:00, 5.30MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\micha\\.cache\\kagglehub\\datasets\\humansintheloop\\semantic-segmentation-of-aerial-imagery\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"humansintheloop/semantic-segmentation-of-aerial-imagery\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SegmentationGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_dir, mask_dir, batch_size, image_size):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_filenames = os.listdir(image_dir)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_files = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        images, masks = [], []\n",
    "\n",
    "        for filename in batch_files:\n",
    "            img = Image.open(os.path.join(self.image_dir, filename)).resize(self.image_size)\n",
    "            mask_name = filename.replace('.jpg', '_mask.png')\n",
    "            mask = Image.open(os.path.join(self.mask_dir, mask_name)).resize(self.image_size)\n",
    "\n",
    "            images.append(np.array(img) / 255.0)\n",
    "            masks.append(np.array(mask))\n",
    "\n",
    "        return np.array(images), np.array(masks)\n",
    "\n",
    "# Instantiate generator\n",
    "images_path = r\"C:\\Users\\micha\\.cache\\kagglehub\\datasets\\bulentsiyah\\semantic-drone-dataset\\versions\\6\\dataset\\semantic_drone_dataset\\original_images\"\n",
    "mask_path   = r\"C:\\Users\\micha\\.cache\\kagglehub\\datasets\\bulentsiyah\\semantic-drone-dataset\\versions\\6\\RGB_color_image_masks\\RGB_color_image_masks\"\n",
    "\n",
    "train_gen = SegmentationGenerator(images_path, mask_path, batch_size=4, image_size=(256, 256))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-segmentation",
   "language": "python",
   "name": "semantic-segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
